{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy           \n",
    "import pandas as pd     \n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def twitter_setup():\n",
    "    \"\"\"\n",
    "    Function to configure the Twitter API with access codes.\n",
    "    \"\"\"\n",
    "    # Tweepy Access codes\n",
    "    CONSUMER_KEY = '' \n",
    "    CONSUMER_SECRET = ''\n",
    "    ACCESS_TOKEN = ''\n",
    "    ACCESS_SECRET = ''\n",
    "    \n",
    "    # authentication and access using keys\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "    # access to the API\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)\n",
    "    return api \n",
    "\n",
    "\n",
    "# creates a extractor object\n",
    "extractor = twitter_setup()\n",
    "\n",
    "# hashtag to get tweets\n",
    "hashtag = \"#8M\"\n",
    "\n",
    "# final time of extraction\n",
    "stop_time = datetime(2019, 5, 9, 10, 55, 0)\n",
    "\n",
    "# some variables to initialize\n",
    "tweets_replies = []\n",
    "df_list_final = []\n",
    "i = 1\n",
    "count = 0\n",
    "\n",
    "while datetime.now() < stop_time:\n",
    "    \n",
    "    # method to extract tweets, it has some parameters to select keywords in tweets, language of tweets, retweets flag, etc.\n",
    "    temp = extractor.search(q = hashtag, result_type=\"recent\", lang = \"es\", include_rts = False, exclude_replies = True, include_entities = True)\n",
    "    tweets_replies.append(temp) \n",
    "    for tweets in tweets_replies:\n",
    "        data_iter = pd.DataFrame(data=[elem.text for elem in tweets], columns=['tweets'])\n",
    "    \n",
    "    # creates all columns of the final dataframe, iterating on each corresponding label for each tweet\n",
    "    data_iter['tweet_long'] = np.array([len(tweet.text) for tweet in tweets])\n",
    "    data_iter['id'] = np.array([tweet.id for tweet in tweets])\n",
    "    data_iter['created_date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "    data_iter['source'] = np.array([tweet.source for tweet in tweets])\n",
    "    data_iter['likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "    data_iter['RTs'] = np.array([tweet.retweet_count for tweet in tweets])\n",
    "    data_iter['language'] = np.array([tweet.lang for tweet in tweets])\n",
    "    data_iter['place'] = np.array([tweet.place for tweet in tweets])\n",
    "    data_iter['user_id'] = np.array([tweet.user.id for tweet in tweets])\n",
    "    data_iter['user_name'] = np.array([tweet.user.name for tweet in tweets])\n",
    "    data_iter['user_description'] = np.array([tweet.user.description for tweet in tweets])\n",
    "    data_iter['followers'] = np.array([tweet.user.followers_count for tweet in tweets])\n",
    "    data_iter['followings'] = np.array([tweet.user.friends_count for tweet in tweets])\n",
    "    data_iter['user_lists_member'] = np.array([tweet.user.listed_count for tweet in tweets])\n",
    "    data_iter['user_total_favourites_count'] = np.array([tweet.user.favourites_count for tweet in tweets])\n",
    "    data_iter['user_statuses_count'] = np.array([tweet.user.statuses_count for tweet in tweets])\n",
    "    data_iter['user_created_account'] = np.array([tweet.user.created_at for tweet in tweets])\n",
    "    data_iter['user_location'] = np.array([tweet.user.location for tweet in tweets])\n",
    "    data_iter['user_lang'] = np.array([tweet.user.lang for tweet in tweets])\n",
    "    \n",
    "    # updates the number of extracted tweets\n",
    "    count += data_iter.shape[0]\n",
    "    \n",
    "    # concatenates to the final dataframe\n",
    "    df_list_final.append(data_iter)\n",
    "    \n",
    "    i += 1\n",
    "    if i % 5 == 0:\n",
    "        print(\"Iteration number %d, %d tweets\" % (i, count))\n",
    "    time.sleep(30)\n",
    "    \n",
    "print(\"----- End of proccess -----\")\n",
    "\n",
    "# gets the final dataframe with all columns and extracted tweets\n",
    "final_df = pd.concat(df_list_final, axis = 0, join = \"outer\")\n",
    "\n",
    "# saves dataframe to .csv file\n",
    "final_df.to_csv('raw_tweets.csv', sep='|', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
