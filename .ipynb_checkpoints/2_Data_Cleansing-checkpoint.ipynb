{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleansing is the most important process in all data science work.\n",
    "The purpose of this notebook is to get cleaned data of *Tweets* column. As a social networks, informal language is used on Twitter and there could be misprint words, specific elements as hashtags, users name, links, etc. In order to clean data from these cases, we will perform the following actions:\n",
    "\n",
    "- Round 0: remove extra spaces. \n",
    "- Round 1: remove mentions, hashtags, links or URLs and \"RT\" words.\n",
    "- Round 2: set text to lowercase, remove all punctuation marks and remove numbers that are contained on words.\n",
    "- Round 3: remove accent marks.\n",
    "- Round 4: remove repeated letters on words.\n",
    "- Round 5: convert laught expressions into a representative word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the libraries and configuring some settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('max_colwidth',150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we load the processed data from the input csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/3_Data_Cleansing_8M.csv\", sep=\"|\", lineterminator='\\n', low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5.301 registers and 20 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 0:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following processes will replace, modify or delete the dirty or coarse data from \"Tweets\" column, specifically:\n",
    "\n",
    "- Spaces at the begining and the end of tweets\n",
    "- Extra spaces\n",
    "- Return (\\r)\n",
    "- New line (\\n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets'] = df['tweets'].map(lambda x: x.replace(\"\\n\",\"\").replace(\"\\r\",\" \").replace(\"  \",\" \").strip())\n",
    "df['tweets'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sample tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sample1 = df['tweets'].iloc[3]\n",
    "tweet_sample2 = df['tweets'].iloc[3]\n",
    "tweet_sample3 = df['tweets'].iloc[3]\n",
    "tweet_sample4 = df['tweets'].iloc[3]\n",
    "tweet_sample5 = df['tweets'].iloc[1432]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 1:\n",
    "\n",
    "First round consists on removing some elements on tweets, the result will be tweets without:\n",
    "- user mentions \n",
    "- hashtags \n",
    "- links or URLs starting with \"https://\"\n",
    "- \"RT\" words\n",
    "- \"vía\" words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_tweets(text, letters):\n",
    "    \"\"\"\n",
    "    Function that receives a text and a list of elements to be remove from the text. \n",
    "    The output will be the initial text without words that start with those elements.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    for letter in letters:\n",
    "        clean_text = []\n",
    "        for word in words:\n",
    "            if not word.startswith(letter):\n",
    "                clean_text.append(word)\n",
    "        words = clean_text\n",
    "        clean_text = ' '.join(clean_text)\n",
    "    return clean_text\n",
    "\n",
    "round1 = lambda x: cleaning_tweets(x,[\"@\", \"#\", \"https://\", \"RT\", \"vía\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets'] = df['tweets'].map(round1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample how the cleaned tweet variable looks like after Round 0 and Round 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original tweet -> \" + tweet_sample1)\n",
    "print(\"Cleaned tweet -> \" + df[\"tweets\"].iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 2 :\n",
    "\n",
    "Second round consists on:\n",
    "\n",
    "- set text to lowercase.\n",
    "- remove all punctuation marks\n",
    "- remove numbers that are contained on words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\" \n",
    "    Function that receives a text.\n",
    "    It returns the text into lowercase, \n",
    "    without text in square brackets, without punctuation marks (except #) and without numbers contained on words.\n",
    "    \"\"\"\n",
    "    puntuation = string.punctuation.replace(\"#\", \"\") + \"¿¡...“”\"\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?¿\\]\\%', ' ', text)\n",
    "    text = re.sub('[%s]' % re.escape(puntuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text).replace(\"\\n\",\"\").replace(\"\\r\",\" \").replace(\"  \",\" \").strip()\n",
    "    return text\n",
    "\n",
    "round2 = lambda x: remove_punctuation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets'] = df['tweets'].map(round2)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample how the cleaned tweet variable looks like after Round 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original tweet -> \" + tweet_sample2)\n",
    "print(\"Cleaned tweet -> \" + df[\"tweets\"].iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 3: \n",
    "Third round consist on remove accent marks on tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_accent_mark(word):\n",
    "    \"\"\"\n",
    "    Function that receives a word.\n",
    "    It returns the words without accent marks.\n",
    "    \"\"\"\n",
    "    \n",
    "    s = ''.join((c for c in unicodedata.normalize('NFD',word) if unicodedata.category(c) != 'Mn'))\n",
    "    return s\n",
    "\n",
    "round3 = lambda x: delete_accent_mark(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets'] = df['tweets'].map(round3)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample how the cleaned tweet variable looks like after Round 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original tweet -> \" + tweet_sample3)\n",
    "print(\"Cleaned tweet -> \" + df[\"tweets\"].iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 4: \n",
    "\n",
    "On this round, some misprints words will be corrected, we will define a function to remove repeated letters, e.g: \n",
    "\"holaa\" >> \"hola\"\n",
    "\n",
    "We consider some cases in Spanish language where it is correct, e.g.:\n",
    "\n",
    "- \"c\"  -> \"acceder\"\n",
    "- \"e\"  -> \"leed\"\n",
    "- \"l\"  -> \"llama\" \n",
    "- \"nn\" -> \"innato\"\n",
    "- \"r\"  -> \"perro\"\n",
    "- \"s\"  -> \"impossible\"\n",
    "- \"p\"  -> \"pp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_repeted_letters(text):\n",
    "    \"\"\"\n",
    "    Function that receives a text to find words with repeated letters on it.\n",
    "    It returns the text without repeated letters.\n",
    "    \"\"\"\n",
    "    result_text = []\n",
    "    spanish_comun_doble_letters = [\"c\",\"e\",\"l\",\"n\",\"r\",\"s\",\"p\"] \n",
    "    \n",
    "    for i in range(0,len(text)):\n",
    "        if text[i] != text[i-1] or i == 0 or (text[i] in spanish_comun_doble_letters):\n",
    "            result_text.append(text[i])\n",
    "    result_text = ''.join(result_text)\n",
    "    return result_text\n",
    "\n",
    "round4 = lambda x : delete_repeted_letters(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets'] = df['tweets'].map(round4)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample how the cleaned tweet variable looks like after Round 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original tweet -> \" + tweet_sample4)\n",
    "print(\"Cleaned tweet -> \" + df[\"tweets\"].iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round 5:\n",
    "\n",
    "Also, informal language contains expression that represent laught. In these round we will normalize these expressions and replace it with a unique word that represent it. \n",
    "The following function expressions like this will be normalize:\n",
    "- \"jajaja\" >> \"LOL\"\n",
    "- \"jejeje\" >> \"LOL\"\n",
    "- \"jijijijiji\" >> \"LOL\"\n",
    "- \"hahahaha\" >> \"LOL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_laught(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that receives a text to find laught expression.\n",
    "    It returns the text with laught expression replace with \"LOL\".\n",
    "    \"\"\"\n",
    "    \n",
    "    new_text = []\n",
    "    laught_normalizer_word = 'LOL'\n",
    "    for word in text.split():\n",
    "        if re.match('jaja', word) or re.match('ajaj', word) or re.match('jeje', word) or re.match('ejej', word) or re.match('haha', word) or re.match('ahah', word) or re.match('jiji', word) or re.match('ijij', word):\n",
    "            word = word.replace(word, laught_normalizer_word)\n",
    "        new_text.append(word)\n",
    "    \n",
    "    result = ' '.join(new_text)\n",
    "    return result \n",
    "\n",
    "round5 = lambda x : replace_laught(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets'] = df['tweets'].map(round5)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample how the cleaned tweet variable looks like after Round 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original tweet -> \" + tweet_sample5)\n",
    "print(\"Cleaned tweet -> \" + df[\"tweets\"].iloc[1432])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have finished all cleansing rounds, we will remove registers with empty tweets and also repeated tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_empty_tweets = df[df[\"tweets\"] != \"\"]\n",
    "df_cleaned = pd.DataFrame(data=df_no_empty_tweets[\"tweets\"].unique(), columns=[\"tweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge unique values with rest of the columns to get the final dataframe with cleaned tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_cleaned, df.sort_values(\"created_date\", ascending=True), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing repeated tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminando tweets repetidos\n",
    "df_final = df_final.drop_duplicates('tweets', keep='first')\n",
    "df_final['tweets'] = df_final['tweets'].map(lambda x: x.replace(\"\\n\",\"\").replace(\"\\r\",\" \").replace(\"  \",\" \").strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we remove possible extra spaces at the rest of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['tweets']           = df_final['tweets'].map(lambda x: x.replace(\"\\n\",\"\").replace(\"\\r\",\" \").replace(\"  \",\" \").strip())\n",
    "df_final['source']           = df_final['source'].map(lambda x: x.replace(\"\\n\",\"\").replace(\"\\r\",\" \").replace(\"  \",\" \").strip())\n",
    "df_final['language']         = df_final['language'].map(lambda x: x.replace(\"\\n\",\"\").replace(\"\\r\",\" \").replace(\"  \",\" \").strip())\n",
    "df_final['place']            = df_final['place'].map(lambda x: str(x).replace(\"\\n\",\"\").replace(\"\\r\",\" \").replace(\"  \",\" \").strip())\n",
    "df_final['user_description'] = df_final['user_description'].map(lambda x: str(x).replace(\"\\n\",\"\").replace(\"\\r\",\" \").replace(\"  \",\" \").strip())\n",
    "df_final['user_name']        = df_final['user_name'].map(lambda x: str(x).replace(\"\\n\",\"\").replace(\"\\r\",\" \").replace(\"  \",\" \").strip())\n",
    "df_final['user_location']    = df_final['user_location'].map(lambda x: str(x).replace(\"\\n\",\"\").replace(\"\\r\",\" \").replace(\"  \",\" \").strip())\n",
    "df_final['user_lang\\r']      = df_final['user_lang\\r'].map(lambda x: x.replace(\"\\n\",\"\").replace(\"\\r\",\" \").replace(\"  \",\" \").strip())\n",
    "df_final['user_lang']        = df_final['user_lang\\r']\n",
    "df_final.drop(\"user_lang\\r\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we get the cleaned dataframe with a total of 4.866 registers and 20 columns. It is saved in a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('cleaned_tweets.csv', \n",
    "                index=False, \n",
    "                header=True,\n",
    "                sep='|',\n",
    "                decimal=',', \n",
    "                encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
